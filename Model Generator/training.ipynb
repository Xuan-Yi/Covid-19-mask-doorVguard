{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KkxewrlTO7LX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()  # 釋放占用的GPU記憶體\n",
        "# 讓cuDNN尋找最快速的卷積演算法 (如果沒裝CUDA應該就不會裝cuDNN，所以應該就刪掉它)\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XggMdLLAfn_O"
      },
      "source": [
        "### Creating image datasets an data loaders for train and test using the experiments folder split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GRqgwzWbO7MI"
      },
      "outputs": [],
      "source": [
        "folder = \"./experiments\"\n",
        "data_path = os.path.join(folder, \"data\")  # data\n",
        "experiments_path = os.path.join(folder, \"dest_folder\")  # dest_folder\n",
        "\n",
        "mask_tags = [\"with_black_mask\", \"with_blue_mask\", \"with_white_mask\"]\n",
        "\n",
        "dataset_without_mask, dataset_with_mask = [], []\n",
        "\n",
        "# rebuilt folder experiments with ../Data Generator/data\n",
        "if os.path.isdir(folder):\n",
        "    shutil.rmtree(folder)\n",
        "os.mkdir(folder)\n",
        "os.mkdir(data_path)\n",
        "os.mkdir(experiments_path)\n",
        "os.mkdir(os.path.join(data_path, \"with_mask\"))\n",
        "source_path = \"../Data Generator/data/\"\n",
        "\n",
        "# built ./experiments/data/without_mask\n",
        "try:\n",
        "    shutil.copytree(os.path.join(source_path, \"without_mask\"),\n",
        "                    os.path.join(data_path, \"without_mask\"))\n",
        "    dataset_without_mask = os.listdir(os.path.join(data_path, \"without_mask\"))\n",
        "except Exception as e:\n",
        "    print(\"Error(without_mask): \", e)\n",
        "# built ./experiments/data/with_mask\n",
        "for f in os.listdir(os.path.join(source_path, \"without_mask\")):\n",
        "    tag = mask_tags[random.randint(0, 2)]\n",
        "    img = os.path.join(source_path, tag, f)\n",
        "    if os.path.isfile(img):\n",
        "        try:\n",
        "            shutil.copy(img, os.path.join(data_path, \"with_mask\"))\n",
        "            dataset_with_mask.append(f)\n",
        "        except Exception as e:\n",
        "            print(\"Error(with_mask): \", e)\n",
        "# split train, test dataset\n",
        "train_data1, test_data1 = train_test_split(\n",
        "    dataset_without_mask, test_size=0.1, shuffle=True, random_state=None)\n",
        "train_data2, test_data2 = train_test_split(\n",
        "    dataset_with_mask, test_size=0.1, shuffle=True, random_state=None)\n",
        "# create train.csv\n",
        "train_data = train_data1+train_data2\n",
        "train_class_list = [\"with_mask\"] * \\\n",
        "    len(train_data1)+[\"without_mask\"]*len(train_data2)\n",
        "train_df = pd.DataFrame(list(zip(train_data, train_class_list)), columns=[\n",
        "                        'filename', 'class'])\n",
        "train_df.to_csv(os.path.join(experiments_path, \"train.csv\"), index=False)\n",
        "# create test.csv\n",
        "test_data = test_data1+test_data2\n",
        "test_class_list = [\"with_mask\"] * \\\n",
        "    len(test_data1)+[\"without_mask\"]*len(test_data2)\n",
        "test_df = pd.DataFrame(list(zip(test_data, test_class_list)), columns=[\n",
        "                       'filename', 'class'])\n",
        "test_df.to_csv(os.path.join(experiments_path, 'test.csv'), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jTcMQewBO7MV"
      },
      "outputs": [],
      "source": [
        "def get_train_files_path(experiments_path, data_path, phase):\n",
        "    if phase == 'train':\n",
        "        file_name = 'train.csv'\n",
        "    elif phase == 'test':\n",
        "        file_name = 'test.csv'\n",
        "    else:\n",
        "        print(\"phase can only have train and test as parameter values\")\n",
        "        exit()\n",
        "    # train.csv或test.csv的路徑\n",
        "    file_path = os.path.join(experiments_path, file_name)\n",
        "    # CSV = Comma-Separated Values\n",
        "    train_df = pd.read_csv(file_path, delimiter=',')\n",
        "    files_path = []\n",
        "    fonts_class = []\n",
        "    for row in train_df.iterrows():\n",
        "        # 圖檔在with_mask或without_mask資料夾中的路徑\n",
        "        files_path.append(os.path.join(\n",
        "            data_path, row[1]['class'], row[1]['filename']))\n",
        "        fonts_class.append(row[1]['class'])  # 圖檔類型(with_mask, without_mask)\n",
        "\n",
        "    return files_path, fonts_class  # 回傳圖檔路徑、類型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FwIrOLLWO7Mb"
      },
      "outputs": [],
      "source": [
        "# 用來將.jpg圖檔從data資料夾複製到train或test資料夾中的with_mask和without_mask子資料夾\n",
        "def copy_images_to_path(file_path, file_class, destination_dir):\n",
        "    font_folder = os.path.join(destination_dir, file_class)  # train或test資料夾路徑\n",
        "    # 若with_mask、without_mask資料夾不存在，新增資料夾\n",
        "    if os.path.exists(font_folder) == False:\n",
        "        os.makedirs(font_folder)\n",
        "\n",
        "    print(\"File being copied from {}:{}\".format(file_path, font_folder))\n",
        "    shutil.copy(file_path, font_folder)  # 從data資料夾複製圖檔(包含存取權)到train或test資料夾\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9PDAY5cZO7Mi"
      },
      "outputs": [],
      "source": [
        "# 由train.csv取得train資料夾的.jpg圖檔在data資料夾中的路徑和類型(with_mask, without_mask)\n",
        "X_train, y_train = get_train_files_path(\n",
        "    experiments_path, data_path, phase='train')\n",
        "# 由test.csv取得test資料夾的.jpg圖檔在data資料夾中的路徑和類型(with_mask, without_mask)\n",
        "X_test, y_test = get_train_files_path(\n",
        "    experiments_path, data_path, phase='test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j79awdvRfoAY"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(experiments_path, 'train')  # trsin資料夾路徑\n",
        "test_dir = os.path.join(experiments_path, 'test')  # test資料夾路徑\n",
        "# 若train資料夾不存在，新增資料夾\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "# 若test資料夾不存在，新增資料夾\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "i2-zOwb8foAg",
        "outputId": "ec785d17-0b90-4e29-d940-7740fe39cb51",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "# 將.jpg圖檔從data資料夾複製到train資料夾\n",
        "for file_path, font_class in zip(X_train, y_train):\n",
        "    try:\n",
        "        copy_images_to_path(file_path, font_class, train_dir)\n",
        "    except Exception as e:\n",
        "        print(\"Error(copy to train): \", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "zDoO05HxfoAr",
        "outputId": "b2820b3c-9ff6-4d93-a0bf-76ec7d265f95",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "# 將.jpg圖檔從data資料夾複製到test資料夾\n",
        "for file_path, font_class in zip(X_test, y_test):\n",
        "    try:\n",
        "        copy_images_to_path(file_path, font_class, test_dir)\n",
        "    except Exception as e:\n",
        "        print(\"Error(copy to test): \", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),  # 將圖片隨機裁剪成(224,224)的大小\n",
        "        transforms.ToTensor(),  # 轉換成Tensor (torch.Tensor是同種資料類型的多維矩陣)\n",
        "        # 標準化：torchvision.transforms.Normalize(mean, std) (output[i] = (input[i]-mean[i])/std[i])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),  # 將圖片縮放成(256,256)\n",
        "        transforms.CenterCrop(224),  # 從中央將圖片裁剪成(224,224)\n",
        "        transforms.ToTensor(),  # 轉換成Tensor\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [\n",
        "                             0.229, 0.224, 0.225])  # 標準化\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ktDG_Pb9foA0"
      },
      "outputs": [],
      "source": [
        "# 建立數據集字典image_datasets，包含數據集train和test，內容分別是train和test資料夾中經過轉換的圖檔\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(\n",
        "    experiments_path, x), data_transforms[x]) for x in ['train', 'test']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "colab_type": "code",
        "id": "ohe0cV40foA9",
        "outputId": "b570f3c2-14ba-4a1d-a9e8-2ea777f59605"
      },
      "outputs": [],
      "source": [
        "# 顯示數據集train的內容\n",
        "image_datasets['train']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "colab_type": "code",
        "id": "FvDR4qdhfoBG",
        "outputId": "9e95895c-5558-4029-d1ad-44f77300f994"
      },
      "outputs": [],
      "source": [
        "# 顯示數據集test的內容\n",
        "image_datasets['test']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kGKTbdM1foBP"
      },
      "outputs": [],
      "source": [
        "# 定義dataloader字典\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                              # 一次讀取的資料數(訓練時每次平行處理1 batch的資料) (若GPU記憶體無法負荷則改小)\n",
        "                                              batch_size=8,\n",
        "                                              shuffle=True,  # reshuffle the data at every epoch\n",
        "                                              num_workers=4)  # 載入檔案所用的子進程(subprocess)數\n",
        "               for x in ['train', 'test']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "colab_type": "code",
        "id": "0LHUWSi_foBV",
        "outputId": "1b2d338b-d976-4b1b-8d22-ba11de11d4cb"
      },
      "outputs": [],
      "source": [
        "dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-0FcvGXxfoBi"
      },
      "outputs": [],
      "source": [
        "class_names = image_datasets['train'].classes  # with_mask、without_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "ySFVDi-bfoBo",
        "outputId": "4e436fb6-3851-4bc1-ab46-826ca7c53656"
      },
      "outputs": [],
      "source": [
        "class_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jzT-TwiwfoBt"
      },
      "outputs": [],
      "source": [
        "# 指定資料記憶體位置(應該可以理解成處理的裝置)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "tWOkLAD7foBz",
        "outputId": "25ef6778-9d90-48ea-d522-09edbfd98472"
      },
      "outputs": [],
      "source": [
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hcKU9_VAfoB6"
      },
      "outputs": [],
      "source": [
        "# 數據集大小(圖片數)\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_sizes['train']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_sizes['test']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ekOc0OegfoB_"
      },
      "source": [
        "### Visualizing images (not the must)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nuQESR5tfoCB"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = (inp-mean)/std\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(inp)\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AAcVhCPFfoCI"
      },
      "outputs": [],
      "source": [
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "colab_type": "code",
        "id": "r6c01nqAfoCP",
        "outputId": "58f0a3c4-40a9-457d-e4d3-27b7e033e814"
      },
      "outputs": [],
      "source": [
        "imshow(out, title=[class_names[x] for x in classes])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tUO8v_WEfoCV"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wv_Xg4LQfoCW"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=1):\n",
        "    since = time.time()  # 訓練開始時間\n",
        "    best_acc = 0.0  # 紀錄最佳精確度\n",
        "    best_model = copy.deepcopy(model.state_dict())  # 紀錄最佳模型\n",
        "\n",
        "    new_freeze_state = None\n",
        "    prev_freeze_state = False\n",
        "    for epoch in range(num_epochs):\n",
        "        # print \"Epoch 0/19\", for example\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # 設為訓練模式\n",
        "            else:\n",
        "                model.eval()  # 設為評估模式\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # 將inputs(影像)、labels(標籤，with_mask、without_mask)轉移到device\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()  # 梯度歸零\n",
        "\n",
        "                # 若phase == 'train'，啟動梯度運算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)  # 　取得模型輸出結果\n",
        "                    # 回傳outputs(Tensor)中(每行元素中的最大值,在該行中的位置(列索引))，資料類型：tensor\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # 用損失函數計算loss，loss是一個tensor\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  # 計算梯度\n",
        "                        optimizer.step()  # 讓optimizer可以做事(利用損失函數優化模型)\n",
        "                        scheduler.step()  # 讓scheduler可以做事(依照設定調整學習率)\n",
        "\n",
        "                # lose.item()將loss從tensor轉成float32，loss.item()*batchsize = loss in abatch\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # 計算模型結果與實際的相似度(？)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / \\\n",
        "                dataset_sizes[phase]  # 此epoch中的損失(與真實數據的落差)\n",
        "            epoch_acc = running_corrects.double(\n",
        "            ) / dataset_sizes[phase]  # 此epoch中的精確度\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc:{:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 若此次訓練模型較好，則取代舊模型\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model = copy.deepcopy(model.state_dict())  # 紀錄最佳模型\n",
        "\n",
        "            print()\n",
        "\n",
        "    time_elapsed = time.time() - since  # 訓練總時間\n",
        "    print('Training complete in {:0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model)  # 加載模型\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1riiyfy4foCq"
      },
      "outputs": [],
      "source": [
        "# 使用已訓練的模型：resnet101\n",
        "model_ft = models.resnet101(pretrained=True)\n",
        "\n",
        "# 修改resnet101模型\n",
        "num_frts = model_ft.fc.in_features  # 提取fc層的固定參數\n",
        "# 將維度從num_frts修改為len(class_names)=2，也就是將原本resnet101模型的fc層1000種類別改成我們要的兩種類別：with_maask、without_mask\n",
        "model_ft.fc = nn.Linear(num_frts, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)  # 將模型轉移到device('cpu'或'cuda')上\n",
        "criterion = nn.CrossEntropyLoss()  # 使用損失函數CrossEntropyLoss()，loss可代表模型與實際狀況的誤差\n",
        "\n",
        "# 使用SGD優化算法，lr(learing rate) = 0.01，動量 = 0.9\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.02, momentum=1.0)\n",
        "# V = beta*V-lr*(dCriterion/dWeight)，W = W + V\n",
        "# 使用學習率調整函數StepLR()，每step_size個epoch會將學習率調整為gamma倍\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "A6VJ-wVZfoCv",
        "outputId": "45c796b3-cba3-4800-9194-312d3126157c"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
        "                           exp_lr_scheduler, num_epochs=3)  # 訓練模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tMzRbxk6kl9u"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft, \"../mask_recognition_model.pth\")  # 儲存模型為.pth檔\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PR.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "metadata": {
      "interpreter": {
        "hash": "6a3e34e222189c0756ab50c7e38e19053e0db080afbca923812458338f6ccb54"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
